{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType,db,connections, AnnSearchRequest\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "\n",
    "# CLUSTER_DOMAIN=\"host.docker.internal\"\n",
    "CLUSTER_DOMAIN = \"localhost\"\n",
    "PORT = 19530\n",
    "CLUSTER_ENDPOINT = f\"http://{CLUSTER_DOMAIN}:{PORT}\"\n",
    "DATABASE_NAME = \"HSBC\"\n",
    "COLLECTION_NAME = \"banks_earnings_calls\"\n",
    "VECTOR_DB_USERNAME = \"developers\"\n",
    "VECTOR_DB_PASSWORD = \"developers\"\n",
    "\n",
    "DEFAULT_EMBEDDING_MODEL_NAME = 'BAAI/bge-m3'\n",
    "\n",
    "KG_URI = \"neo4j://localhost:7687\"\n",
    "KG_USER = \"neo4j\"\n",
    "KG_PASSWORD=\"meCfTH39XssP92e\"\n",
    "\n",
    "CHUNKS_SEPRATOR_STRING = \"\\n\\n\"\n",
    "MAX_APPROXIMATE_TOKENS = 1280000\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri=KG_URI, user=KG_USER, password=KG_PASSWORD):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            return list(session.run(query, parameters))\n",
    "        \n",
    "class OrderedSet:\n",
    "    def __init__(self):\n",
    "        self.dict = {}\n",
    "\n",
    "    def add(self, value):\n",
    "        self.dict[value] = None\n",
    "\n",
    "    def remove(self, value):\n",
    "        if value in self.dict:\n",
    "            del self.dict[value]\n",
    "\n",
    "    def __contains__(self, value):\n",
    "        return value in self.dict\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dict)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({list(self.dict.keys())})\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return list(self.dict.keys())[index]\n",
    "class RAG:\n",
    "    model = None\n",
    "    reranker = None\n",
    "    def __init__(self,milvus_client=MilvusClient(db_name=DATABASE_NAME,uri=CLUSTER_ENDPOINT,user=VECTOR_DB_USERNAME,password=VECTOR_DB_PASSWORD),\n",
    "                 neo4j_connection=Neo4jConnection(),\n",
    "                 max_approximate_tokens=MAX_APPROXIMATE_TOKENS):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.neo4j_connection = neo4j_connection\n",
    "        self.max_approximate_tokens=max_approximate_tokens\n",
    "        pass\n",
    "    \n",
    "    def words_size_to_approximate_tokens_size(words_size):\n",
    "        return int(words_size * (4/3))\n",
    "    def approximate_tokens_counter(document:str):\n",
    "        words_size=len(document.split())\n",
    "        tokens_size=RAG.words_size_to_approximate_tokens_size(words_size)\n",
    "        return tokens_size\n",
    "    def format_rag_documents(documents_map:dict):\n",
    "        rag_docoment=\"\"\n",
    "        for key in documents_map:\n",
    "            rag_docoment+=f\"The following is document for {key}:\\n\\n{documents_map[key]}\"\n",
    "        return rag_docoment\n",
    "    \n",
    "    def get_embeddings(self, queries)->dict[str, np.ndarray]:\n",
    "        from FlagEmbedding import BGEM3FlagModel\n",
    "        if RAG.model is None:\n",
    "            RAG.model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "            RAG.model.model.to('cuda')\n",
    "            print(\"Model loaded.\")\n",
    "        embeddings = self.model.encode(queries, return_dense=True, return_sparse=True, return_colbert_vecs=False)\n",
    "        dense_vectors = embeddings['dense_vecs']\n",
    "        lexical_weights = embeddings['lexical_weights']\n",
    "        return {\"dense_vectors\": dense_vectors, \"sparse_vectors\": lexical_weights}\n",
    "    def similarity_sort(self,sentences_1 :list[str], sentences_2 :list[str]):\n",
    "        embeddings_1 =self.get_embeddings(sentences_1)['dense_vectors']\n",
    "        embeddings_2 =self.get_embeddings(sentences_2)['dense_vectors']\n",
    "        similarity = embeddings_1 @ embeddings_2.T\n",
    "        sorted_sentences_2 = [sentences_2[i] for i in similarity.argsort()[0][::-1]]\n",
    "        return sorted_sentences_2\n",
    "    def rerank(self,query:str,records:list,topk):\n",
    "        from FlagEmbedding import FlagReranker\n",
    "        if self.reranker is None:\n",
    "            self.reranker = FlagReranker('BAAI/bge-reranker-base', use_fp16=True)\n",
    "            self.reranker.model.to('cuda')\n",
    "            print(\"Reranker loaded.\")\n",
    "        chunks=[]\n",
    "        for record in records:\n",
    "            content=record[\"entity\"][\"content\"]\n",
    "            summary=record[\"entity\"][\"summary\"]\n",
    "            full_summary:str=record[\"entity\"][\"full_summary\"]\n",
    "            chunk=full_summary.replace(summary,content)\n",
    "            chunks.append(chunk)\n",
    "            chunk=record[\"entity\"][\"content\"]\n",
    "            chunks.append(chunk)\n",
    "        rerank_pairs=[(query,chunk) for chunk in chunks]\n",
    "        reranker_scores=self.reranker.compute_score(rerank_pairs,batch_size=32)\n",
    "        best_documents=self.sort_by_reranker_scores(records,reranker_scores)\n",
    "        best_documents=best_documents[:topk]\n",
    "        df=pd.DataFrame(best_documents)\n",
    "        df.to_json(\"reranked.jsonl\",orient=\"records\",lines=True)\n",
    "        return best_documents\n",
    "    def sort_by_reranker_scores(self,documents,reranker_scores):\n",
    "        # print(reranker_scores)\n",
    "        # print(documents)\n",
    "        # return [doc for _, doc in sorted(zip(reranker_scores, documents), reverse=True)]\n",
    "        paired_list = list(zip(reranker_scores, documents))\n",
    "        paired_list.sort(key=lambda x: x[0], reverse=True)\n",
    "        sorted_documents = [doc for _, doc in paired_list]\n",
    "        return sorted_documents\n",
    "    def filter_unique_knowledge_graph_old(results):\n",
    "        unique_kg_set=dict()\n",
    "        for result in results[0]:\n",
    "            hash_id=result[\"entity\"]['hash']\n",
    "            if hash_id not in unique_kg_set:\n",
    "                if \"cypher\" in result[\"entity\"]:\n",
    "                    unique_kg_set[hash_id]={\"cypher\":result['entity']['cypher']}\n",
    "                else:\n",
    "                    unique_kg_set[hash_id]={\"hash\":hash_id}\n",
    "        return unique_kg_set\n",
    "    def filter_unique_unique_hash_id(results):\n",
    "        unique_kg_set=OrderedSet()\n",
    "        for result in results:\n",
    "            hash_id=result[\"entity\"]['hash']\n",
    "            if hash_id not in unique_kg_set:\n",
    "                unique_kg_set.add(hash_id)\n",
    "        return unique_kg_set\n",
    "    def filter_unique_vector_db(self,results):\n",
    "        chunk_set=OrderedSet()\n",
    "        for result in results:\n",
    "            chunk=result[\"entity\"]['content']\n",
    "            if chunk not in chunk_set:\n",
    "                current_document:str=CHUNKS_SEPRATOR_STRING.join(chunk_set)\n",
    "                if RAG.approximate_tokens_counter(current_document)+RAG.approximate_tokens_counter(chunk) > self.max_approximate_tokens:\n",
    "                    break\n",
    "                chunk_set.add(chunk)\n",
    "        return chunk_set\n",
    "    def retrive_documents(self, query:str, top_v=10, top_r=5):\n",
    "        embeddings:dict[str,np.ndarray]=self.get_embeddings([query])\n",
    "        dense_vectors=embeddings['dense_vectors'].tolist()\n",
    "        dense_search_params = {\"metric_type\": \"IP\"}\n",
    "        res = self.milvus_client.search(COLLECTION_NAME, data=dense_vectors, search_params=dense_search_params, \n",
    "                                 output_fields=[\"id\",\"hash\",\"bank\",\"content\",\"summary\",\"full_summary\"], topk=top_v)\n",
    "        df = pd.DataFrame(res[0])\n",
    "        df.to_json(\"vector_search.jsonl\",orient=\"records\",lines=True)\n",
    "        # return res[0]\n",
    "        response=self.rerank(query,res[0],top_r)\n",
    "        return response\n",
    "    def vector_db_rag(self,query:str,top_v=10, top_r=5)->str:\n",
    "        results=self.retrive_documents(query,top_v, top_r)\n",
    "        documents=self.filter_unique_vector_db(results)\n",
    "        return \"\\n\\n\".join(documents)\n",
    "\n",
    "    def select_via_cypher_query(self,cypher_query:str):\n",
    "        records = self.neo4j_connection.query(cypher_query)\n",
    "        return records\n",
    "    def select_via_chunks(self,hash_id):\n",
    "        query = \"\"\"MATCH (c:Chunk {hash: $hash})-[:HAS_CHUNK]-(b:Bank)\n",
    "OPTIONAL MATCH (c)-[:SPOKE_IN]-(s:Speaker)\n",
    "RETURN c as chunk, b as bank, collect(s) AS speakers\"\"\"\n",
    "        records = self.neo4j_connection.query(query,{\"hash\":hash_id})\n",
    "        return records\n",
    "    def format_default_kg_chunks_rag_documents_old(self,kg_sets:dict)->str:\n",
    "        documents_map:dict[str,str]={}\n",
    "        for hash_id,kg_set in kg_sets.items():\n",
    "            if \"cypher\" in kg_set:\n",
    "                records=self.select_via_cypher_query(kg_set[\"cypher\"])\n",
    "                for record in records:\n",
    "                    bank_name=kg_set[\"cypher\"]\n",
    "            else:\n",
    "                records=self.select_via_chunks(hash_id)\n",
    "                for record in records:\n",
    "                    bank = record[\"bank\"]\n",
    "                    bank_name=bank[\"name\"]\n",
    "                    chunk=record[\"chunk\"]\n",
    "                    summary=chunk[\"summary\"]\n",
    "                    original_text=chunk[\"chunk\"]\n",
    "                    full_summary:str=bank[\"full_summary\"]\n",
    "                    temp_documents_map:dict[str,str]=json.loads(json.dumps(documents_map))\n",
    "                    if bank_name not in temp_documents_map:\n",
    "                        temp_documents_map[bank_name]=f\"{bank_name}'s 2024 Q1 Earnings Call:\\n{full_summary.replace(summary,original_text)}\"\n",
    "                    else:\n",
    "                        temp_documents_map[bank_name].replace(summary,original_text)\n",
    "                    if RAG.approximate_tokens_counter(RAG.format_rag_documents(temp_documents_map))>self.max_approximate_tokens:\n",
    "                        return documents_map\n",
    "                    documents_map=temp_documents_map\n",
    "                    pass\n",
    "            pass\n",
    "        return documents_map\n",
    "    def format_default_kg_chunks_rag_documents(self,unique_hash_ids:OrderedSet)->str:\n",
    "        documents_map:dict[str,str]={}\n",
    "        for hash_id in unique_hash_ids:\n",
    "            records=self.select_via_chunks(hash_id)\n",
    "            for record in records:\n",
    "                bank = record[\"bank\"]\n",
    "                bank_name=bank[\"name\"]\n",
    "                chunk=record[\"chunk\"]\n",
    "                summary=chunk[\"summary\"]\n",
    "                original_text=chunk[\"chunk\"]\n",
    "                full_summary:str=bank[\"full_summary\"]\n",
    "                temp_documents_map:dict[str,str]=json.loads(json.dumps(documents_map))\n",
    "                if bank_name not in temp_documents_map:\n",
    "                    temp_documents_map[bank_name]=f\"{bank_name}'s 2024 Q1 Earnings Call:\\n{full_summary.replace(summary,original_text)}\"\n",
    "                else:\n",
    "                    temp_documents_map[bank_name].replace(summary,original_text)\n",
    "                if RAG.approximate_tokens_counter(RAG.format_rag_documents(temp_documents_map))>self.max_approximate_tokens:\n",
    "                    return documents_map\n",
    "                documents_map=temp_documents_map\n",
    "                pass\n",
    "            pass\n",
    "        return documents_map\n",
    "    def format_default_kg_nodes_rag_documents(self,banks:str,information_type:str)->str:\n",
    "        banks_names=[bank.strip() for bank in banks.split(\",\")]\n",
    "        information_types=[information_type.strip() for information_type in information_type.split(\",\")]\n",
    "        def get_property_values(conn: Neo4jConnection, banks: list, properties: list):\n",
    "            query = \"\"\"\n",
    "            MATCH (b:Bank)-[r:HAS_PROPERTY]->(p:Property)\n",
    "            WHERE b.name IN $banks AND p.name IN $properties\n",
    "            RETURN b.name AS bank, p.name AS property, r.value AS value\n",
    "            \"\"\"\n",
    "            result = conn.query(query, {\"banks\": banks, \"properties\": properties})\n",
    "            return result\n",
    "        records = get_property_values(self.neo4j_connection, banks_names, information_types)\n",
    "        documents_map:dict[str,str]={}\n",
    "        for record in records:\n",
    "            bank=record[\"bank\"]\n",
    "            property=record[\"property\"]\n",
    "            value=record[\"value\"]\n",
    "            if bank not in documents_map:\n",
    "                documents_map[f\"{bank} {property}\"]=value\n",
    "            else:\n",
    "                documents_map[f\"{bank} {property}\"]+=\"\\n\"+value\n",
    "            pass\n",
    "        return documents_map\n",
    "    \n",
    "    def default_knowledge_graph_rag(self,query:str,banks:str,information_type:str):\n",
    "        rag_documents_map:dict={}\n",
    "        rag_documents_map.update(self.format_default_kg_nodes_rag_documents(banks,information_type))\n",
    "        if len(rag_documents_map.keys())<2:\n",
    "            results=self.retrive_documents(query,top_v=10, top_r=3)\n",
    "            unique_hash_id=RAG.filter_unique_unique_hash_id(results)\n",
    "            rag_documents_map.update(self.format_default_kg_chunks_rag_documents(unique_hash_id))\n",
    "        rag_documents_str:str=RAG.format_rag_documents(rag_documents_map)\n",
    "        df=pd.DataFrame(rag_documents_map.items(),columns=[\"bank\",\"content\"])\n",
    "        df.to_json(\"default_knowledge_graph_rag.json\")\n",
    "        return rag_documents_str\n",
    "    \n",
    "    def select_speakers_via_banks(self,banks_names:list[str]|None=None):\n",
    "        if banks_names is None or len(banks_names)==0:\n",
    "            query = \"\"\"MATCH (s:Speaker)-[:ATTENDED]-(b:Bank) RETURN s.name as speakers_names, b.name as banks_names\"\"\"\n",
    "            records = self.neo4j_connection.query(query)\n",
    "            return records\n",
    "        else:\n",
    "            query = \"\"\"MATCH (s:Speaker)-[:ATTENDED]-(b:Bank{name: $bank_name}) RETURN s.name as speakers_names, b.name as banks_names\"\"\"\n",
    "            all_records=[]\n",
    "            for bank_name in banks_names:\n",
    "                records = self.neo4j_connection.query(query,{\"bank_name\":bank_name})\n",
    "                all_records.extend(records)\n",
    "            return all_records\n",
    "    def specific_cypher_query_test_knowledge_graph_rag(self):\n",
    "        records=self.specific_cypher_query_test()\n",
    "        speakers_in_banks_map:dict[str,list]={}\n",
    "        for record in records:\n",
    "            bank_name=record[\"bank_name\"]\n",
    "            speaker_name=record[\"speaker_name\"]\n",
    "            if bank_name not in speakers_in_banks_map:\n",
    "                speakers_in_banks_map[bank_name]=[speaker_name]\n",
    "            else:\n",
    "                speakers_in_banks_map[bank_name].append(speaker_name)\n",
    "            pass\n",
    "        rag_documents_str=\"\"\n",
    "        for bank_name in speakers_in_banks_map:\n",
    "            rag_documents_str+=f\"\\n\\nName List of People who have spoke in Bank < {bank_name} > Earnings Call:\\n\"\n",
    "            rag_documents_str+=\"\\n\".join(speakers_in_banks_map[bank_name])\n",
    "        return rag_documents_str\n",
    "    \n",
    "    def specific_cypher_query_test(self):\n",
    "    # MATCH (s:Speaker)-[r:ATTENDED]->(b:Bank)\n",
    "        query = \"\"\"\n",
    "    MATCH (s:Speaker)-[:SPOKE_IN]->(:Chunk)<-[:HAS_CHUNK]-(b:Bank)\n",
    "    WITH s, COUNT(DISTINCT b) AS bank_count\n",
    "    WHERE bank_count > 1\n",
    "    MATCH (s:Speaker)-[:SPOKE_IN]->(:Chunk)<-[:HAS_CHUNK]-(b:Bank)\n",
    "    RETURN DISTINCT s.name AS speaker_name, b.name AS bank_name\n",
    "    \"\"\"\n",
    "        records = self.neo4j_connection.query(query)\n",
    "        return records\n",
    "    \n",
    "    def cypher_query(self,cypher_query:str,params:dict=None):\n",
    "        if params is None:\n",
    "            records=self.neo4j_connection.query(cypher_query)\n",
    "        else:\n",
    "            records=self.neo4j_connection.query(cypher_query,params)\n",
    "        serialized_records=[]\n",
    "        for record in records:\n",
    "            serialized_record={}\n",
    "            for key in record.keys():\n",
    "                serialized_record[key]=record[key]\n",
    "            serialized_records.append(serialized_record)\n",
    "        return serialized_records\n",
    "rag=RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DifyService import DifyLLMaaS\n",
    "llmaas=DifyLLMaaS(output_path=\"qna_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query:str,document):\n",
    "    print(f\"Approximate tokens size: {RAG.approximate_tokens_counter(document)}\")\n",
    "    # llmaas.cache_delete({\"query\":query,\"document\":document})\n",
    "    response=llmaas.call({\"query\":query,\"document\":document})\n",
    "    return response[\"data\"][\"outputs\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB RAG\n",
      "Approximate tokens size: 1494\n",
      "HSBC's UK loans and deposits have been stable, with the UK economy remaining resilient in terms of inflation and employment. The bank continues to gain market share in mortgages, SME lending, and other areas.\n",
      "\n",
      "My version of Hybird RAG\n",
      "Approximate tokens size: 1780\n",
      "According to the provided documents, HSBC reported:\n",
      "\n",
      "* A profit before tax of $12.7 billion in Q1 2023\n",
      "* A quarterly increase in Risk-Weighted Assets driven primarily by loan growth and asset quality improvements in Asia\n",
      "* Revenue growth to $20.8 billion in Q1 2023\n",
      "* A completion of a $2 billion share buyback\n",
      "* An announcement of an additional $8.8 billion in distributions\n",
      "* A reaffirmation of its 2024 guidance, demonstrating the bank's commitment to strong shareholder returns and a robust global presence.\n",
      "\n",
      "Overall, HSBC's performance on profit appears to be positive, with growth in revenue and a completion of a significant share buyback program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"How does HSBC perform on profit so far?  Give me a short answer.\"\n",
    "banks=\"HSBC\"\n",
    "information_type=\"profit\"\n",
    "vector_db_document=rag.vector_db_rag(query,top_v=10, top_r=3)\n",
    "knowledge_graph_document=rag.default_knowledge_graph_rag(query=query, banks=banks, information_type=information_type)\n",
    "print(\"Vector DB RAG\")\n",
    "answer=get_answer(query,vector_db_document);print(answer);print(\"\")\n",
    "print(\"My version of Hybird RAG\")\n",
    "answer=get_answer(query,knowledge_graph_document);print(answer);print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB RAG\n",
      "Approximate tokens size: 1378\n",
      "Glenn Schorr from Evercore was the one who went to multiple bank's earnings call event as he asked questions on revenue side of the business at Citigroup's earnings call.\n",
      "\n",
      "My version of Hybird RAG\n",
      "Approximate tokens size: 44\n",
      "Perlie Mong attended both Standard Chartered and HSBC's earnings calls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"Who went to multiple banks' earnings calls event? Give me a short and simple answer.\"\n",
    "vector_db_document=rag.vector_db_rag(query,top_v=10, top_r=5)\n",
    "knowledge_graph_document=rag.specific_cypher_query_test_knowledge_graph_rag()\n",
    "print(\"Vector DB RAG\")\n",
    "answer=get_answer(query,vector_db_document);print(answer);print(\"\")\n",
    "print(\"My version of Hybird RAG\")\n",
    "answer=get_answer(query,knowledge_graph_document);print(answer);print(\"\")\n",
    "# print(knowledge_graph_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB RAG\n",
      "Approximate tokens size: 1469\n",
      "Based on the provided document, here's a simple comparison between HSBC and DBS' 2024 plans:\n",
      "\n",
      "**HSBC:**\n",
      "\n",
      "* Reconfirms guidance:\n",
      "\t+ Mid-teens return on tangible equity excluding notable items\n",
      "\t+ Banking NII of at least $41 billion\n",
      "\t+ ECLs of around 40 basis points\n",
      "\t+ Cost growth limited to circa 5% on a target basis\n",
      "\t+ 50% dividend payout ratio\n",
      "* Focused on:\n",
      "\t+ Continuing momentum and execution of strategy\n",
      "\t+ Development of wealth, transaction banking capabilities, and global wholesale banking\n",
      "\n",
      "**DBS:**\n",
      "\n",
      "Unfortunately, there is no mention of DBS' plans for 2024 in the provided document. The conversation only discusses HSBC's performance and guidance for the year.\n",
      "\n",
      "If you'd like to provide more information about DBS' 2024 plans, I can help compare them with HSBC's goals.\n",
      "\n",
      "My version of Hybird RAG\n",
      "Approximate tokens size: 1682\n",
      "Here is a short and simple comparison of HSBC and DBS plans for 2024:\n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* Both banks prioritize shareholder value creation through share buybacks and dividend distributions.\n",
      "* They focus on strategic growth areas like wealth management, global wholesale banking, and transaction banking.\n",
      "* Both emphasize cost management and efficiency to maintain profitability.\n",
      "\n",
      "**Differences:**\n",
      "\n",
      "* **Income Growth:** HSBC expects 2024 NII guidance of at least $41 billion, while DBS anticipates a 6-7% income growth for the near term.\n",
      "* **Capital Management:** DBS aims to increase its capital ratio by 70 basis points, whereas HSBC's focus is on enhanced hedging strategies and asset quality management.\n",
      "* **Loan Growth:** DBS experiences strong loan growth driven by high demand in the commodity sector, whereas HSBC focuses on expanding its Wealth division and Global Payments Solutions.\n",
      "* **Risk Management:** DBS maintains excess GP reserves to cushion against potential stress, while HSBC reaffirmed its 2024 expected credit loss (ECL) guidance at around 40 basis points.\n",
      "\n",
      "These differences reflect distinct strategic priorities and risk management approaches between the two banks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"Can you compare the plan for both HSBC and DBS have in 2024?  Give me a short and simple answer.\"\n",
    "banks=\"HSBC, DBS\"\n",
    "information_type=\"plan\"\n",
    "print(\"Vector DB RAG\")\n",
    "vector_db_document=rag.vector_db_rag(query,top_v=10, top_r=3)\n",
    "answer=get_answer(query,vector_db_document);print(answer);print(\"\")\n",
    "print(\"My version of Hybird RAG\")\n",
    "knowledge_graph_document=rag.default_knowledge_graph_rag(query=query, banks=banks, information_type=information_type)\n",
    "answer=get_answer(query,knowledge_graph_document);print(answer);print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
